{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7976f9bb",
   "metadata": {},
   "source": [
    "# Zillow Clustering Project\n",
    "Sophia Stewart<br>\n",
    "Stephanie Jones<br>\n",
    "Codeup | Data Science, Hopper Cohort<br>\n",
    "Monday, January 10, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4689885",
   "metadata": {},
   "source": [
    "# About the Project\n",
    "#### Goal\n",
    "Identify drivers of error in predicting home value for single family properties<br>\n",
    "#### Why?\n",
    "We want to improve our zestimate home value predictions so that we can better serve those who purchase and sell homes<br>\n",
    "\n",
    "# Data Dictionary\n",
    "### DataFrames\n",
    "| DFs | Meaning |\n",
    "| :-------- | -------: |\n",
    "| zillow   | Full, original dataframe retrieved from the zillow mySQL database |\n",
    "| train    | Sample (56%) of zillow used for exploring data and fitting/training models|\n",
    "| validate | Sample (24%) of zillow used to evaluate multiple models |\n",
    "| test     | Sample (20%) of zillow used to evaluate the best model |\n",
    "\n",
    "### Variables\n",
    "| Target | Meaning |\n",
    "| :-------- | -------: |\n",
    "| logerror | Our target variable; the Zestimate error which we want to minimize |\n",
    "\n",
    "\n",
    "| Variables | Meaning |\n",
    "| :-------- | -------: |\n",
    "| tax_value | The property's tax assessed value |\n",
    "| beds     | Number of bedrooms |\n",
    "| baths    | Number of bathrooms, including fractional bathrooms |\n",
    "| fullbaths | Number of full bathrooms |\n",
    "| latitude | The property's latitude |\n",
    "| longitude | The property's longitude |\n",
    "| sq_ft    | Calculated total finished living area |\n",
    "| yearbuilt | The year the property was built |\n",
    "| age      | The age of the property |\n",
    "| transactiondate | The date the property was sold |\n",
    "\n",
    "<!-- | Clustering | Meaning |\n",
    "| :-------- | -------: |\n",
    "| beds_scaled | Standard-scaled `beds` |\n",
    "| baths_scaled | Standard-scaled `baths` |\n",
    "| sq_ft_scaled | Standard-scaled `sq_ft` |\n",
    "\n",
    "\n",
    "| Modeling | Meaning |\n",
    "| :-------- | -------: |\n",
    "| x_train  | `train`, with scaled `tax_value`, `age`, `sqft` columns |\n",
    "| y_train  | `train`, but only the target |\n",
    "| x_validate | `validate`, with scaled `tax_value`, `age`, `sqft` columns |\n",
    "| y_validate | `validate`, but only the target |\n",
    "| x_test   | `test`, with scaled `tax_value`, `age`, `sqft` columns |\n",
    "| y_test   | `test`, but only the target | -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4328a8",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "High `logerror` threatens our credibility as a primary source of home valuation predictions in the real estate market. We want to find the drivers of Zestimate prediction `logerror` to provide more accurate home valuations. \n",
    "<br><br>\n",
    "To do this, we will use clustering to identify patterns in our 2017 single-unit property data and use those clusters to build a model which will be used for predicting logerror. If we can predict `logerror`, we can use those predictions to make more accurate predictions of home values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f646d42",
   "metadata": {},
   "source": [
    "# Step 1 | Acquire and Wrangle\n",
    "In our `wrangle.py` module you will find the following functions:\n",
    "- `acquire_zillow()` acquires zillow data from a csv file or from a sequel query (see query inside of function within module)\n",
    "- `clean_zillow()` cleans the acquired data\n",
    "    - filter out non-single unit properties using `propertylandusetypeid`, `beds`, `baths`, and `sqft`\n",
    "    - drop null rows and columns with > 50% missing values\n",
    "    - create `age` column from `yearbuilt`\n",
    "    - drop any remaining null values\n",
    "    - correct dtypes for int values\n",
    "    - drop `propertylandusetypeid`, `transactiondate`, `yearbuilt`, `unitcnt`\n",
    "    - remove outliers\n",
    "- `split_zillow(df)` split data into train, validate, and test dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828e21d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (20184, 9)\n",
      "Validate Shape: (6729, 9)\n",
      "Test Shape: (6729, 9)\n"
     ]
    }
   ],
   "source": [
    "import wrangle as w\n",
    "\n",
    "train, validate, test = w.split_zillow(w.clean_zillow(w.acquire_zillow()))\n",
    "\n",
    "print(f'Train Shape: {train.shape}\\nValidate Shape: {validate.shape}\\nTest Shape: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa82370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b75a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f5455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08d14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e62789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15955c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6fa9dcd",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    ">Your conclusion summary should addresses the questions you raised in the opening of the project, which we would want to see at the end of every final notebook. Ideally, when the deliverable is a report, the summary should tie together your analysis, the drivers of the outcome, and how you would expect your ML model to perform in the future on unseen data, in layman's terms.\n",
    "\n",
    "## Recommendations\n",
    ">Your notebook should end with actionable recommendations based on your insights and analysis on a way to make a better model, such as a new feature or an algorithm or something you found that doesn't work.\n",
    "\n",
    "## Next Steps\n",
    ">Your conclusion should include next steps from a data science perspective that will assist in improving your research. Ideally, if you talk about trying more algorithms to improve performance, think about why you need to improve performance. And if the business calls for it, remember the best way to improve performance is to have better predictors/features. If you talk about gathering more data, being specific about what data you think will help you understand the problem better and why is the way to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534986e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
